{
  "best_metric": 0.8712695240974426,
  "best_model_checkpoint": "./results\\checkpoint-1944",
  "epoch": 18.0,
  "eval_steps": 500,
  "global_step": 1944,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.09259259259259259,
      "grad_norm": 86.91573333740234,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 5.4531,
      "step": 10
    },
    {
      "epoch": 0.18518518518518517,
      "grad_norm": 100.32019805908203,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 4.8161,
      "step": 20
    },
    {
      "epoch": 0.2777777777777778,
      "grad_norm": 68.75818634033203,
      "learning_rate": 3e-06,
      "loss": 3.7028,
      "step": 30
    },
    {
      "epoch": 0.37037037037037035,
      "grad_norm": 36.087059020996094,
      "learning_rate": 4.000000000000001e-06,
      "loss": 2.4363,
      "step": 40
    },
    {
      "epoch": 0.46296296296296297,
      "grad_norm": 4.98185396194458,
      "learning_rate": 5e-06,
      "loss": 1.7004,
      "step": 50
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 6.56571102142334,
      "learning_rate": 6e-06,
      "loss": 1.5862,
      "step": 60
    },
    {
      "epoch": 0.6481481481481481,
      "grad_norm": 3.2732350826263428,
      "learning_rate": 7.000000000000001e-06,
      "loss": 1.5348,
      "step": 70
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 2.8108134269714355,
      "learning_rate": 8.000000000000001e-06,
      "loss": 1.4492,
      "step": 80
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 2.744920492172241,
      "learning_rate": 9e-06,
      "loss": 1.4275,
      "step": 90
    },
    {
      "epoch": 0.9259259259259259,
      "grad_norm": 2.519237995147705,
      "learning_rate": 1e-05,
      "loss": 1.3087,
      "step": 100
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.1745526790618896,
      "eval_runtime": 6.0996,
      "eval_samples_per_second": 35.576,
      "eval_steps_per_second": 4.59,
      "step": 108
    },
    {
      "epoch": 1.0185185185185186,
      "grad_norm": 2.3293368816375732,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 1.3307,
      "step": 110
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 2.1873703002929688,
      "learning_rate": 1.2e-05,
      "loss": 1.408,
      "step": 120
    },
    {
      "epoch": 1.2037037037037037,
      "grad_norm": 2.549802541732788,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 1.4009,
      "step": 130
    },
    {
      "epoch": 1.2962962962962963,
      "grad_norm": 2.5427675247192383,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 1.2882,
      "step": 140
    },
    {
      "epoch": 1.3888888888888888,
      "grad_norm": 2.410282611846924,
      "learning_rate": 1.5e-05,
      "loss": 1.361,
      "step": 150
    },
    {
      "epoch": 1.4814814814814814,
      "grad_norm": 2.498802661895752,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 1.2474,
      "step": 160
    },
    {
      "epoch": 1.574074074074074,
      "grad_norm": 1.9190374612808228,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 1.212,
      "step": 170
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 2.4507534503936768,
      "learning_rate": 1.8e-05,
      "loss": 1.1459,
      "step": 180
    },
    {
      "epoch": 1.7592592592592593,
      "grad_norm": 2.641416072845459,
      "learning_rate": 1.9e-05,
      "loss": 1.1694,
      "step": 190
    },
    {
      "epoch": 1.8518518518518519,
      "grad_norm": 2.486887216567993,
      "learning_rate": 2e-05,
      "loss": 1.1787,
      "step": 200
    },
    {
      "epoch": 1.9444444444444444,
      "grad_norm": 2.160099506378174,
      "learning_rate": 2.1e-05,
      "loss": 1.18,
      "step": 210
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.067928671836853,
      "eval_runtime": 6.0976,
      "eval_samples_per_second": 35.588,
      "eval_steps_per_second": 4.592,
      "step": 216
    },
    {
      "epoch": 2.037037037037037,
      "grad_norm": 2.3846445083618164,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 1.3166,
      "step": 220
    },
    {
      "epoch": 2.1296296296296298,
      "grad_norm": 2.770657539367676,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 1.2797,
      "step": 230
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 2.3707921504974365,
      "learning_rate": 2.4e-05,
      "loss": 1.1307,
      "step": 240
    },
    {
      "epoch": 2.314814814814815,
      "grad_norm": 2.5724127292633057,
      "learning_rate": 2.5e-05,
      "loss": 1.2043,
      "step": 250
    },
    {
      "epoch": 2.4074074074074074,
      "grad_norm": 1.9685229063034058,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 1.1369,
      "step": 260
    },
    {
      "epoch": 2.5,
      "grad_norm": 2.954171895980835,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 1.1448,
      "step": 270
    },
    {
      "epoch": 2.5925925925925926,
      "grad_norm": 2.496151924133301,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 1.0957,
      "step": 280
    },
    {
      "epoch": 2.685185185185185,
      "grad_norm": 2.316371202468872,
      "learning_rate": 2.9e-05,
      "loss": 1.1264,
      "step": 290
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 2.708836793899536,
      "learning_rate": 3e-05,
      "loss": 1.1842,
      "step": 300
    },
    {
      "epoch": 2.8703703703703702,
      "grad_norm": 2.3023364543914795,
      "learning_rate": 3.1e-05,
      "loss": 1.0983,
      "step": 310
    },
    {
      "epoch": 2.962962962962963,
      "grad_norm": 2.3955087661743164,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 1.1991,
      "step": 320
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.0255388021469116,
      "eval_runtime": 6.0976,
      "eval_samples_per_second": 35.588,
      "eval_steps_per_second": 4.592,
      "step": 324
    },
    {
      "epoch": 3.0555555555555554,
      "grad_norm": 2.695127248764038,
      "learning_rate": 3.3e-05,
      "loss": 1.0889,
      "step": 330
    },
    {
      "epoch": 3.148148148148148,
      "grad_norm": 3.158748149871826,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 1.1281,
      "step": 340
    },
    {
      "epoch": 3.240740740740741,
      "grad_norm": 2.706834554672241,
      "learning_rate": 3.5e-05,
      "loss": 1.2203,
      "step": 350
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 2.4788074493408203,
      "learning_rate": 3.6e-05,
      "loss": 1.0507,
      "step": 360
    },
    {
      "epoch": 3.425925925925926,
      "grad_norm": 2.855890989303589,
      "learning_rate": 3.7e-05,
      "loss": 1.0548,
      "step": 370
    },
    {
      "epoch": 3.5185185185185186,
      "grad_norm": 2.2991302013397217,
      "learning_rate": 3.8e-05,
      "loss": 1.1006,
      "step": 380
    },
    {
      "epoch": 3.611111111111111,
      "grad_norm": 2.8649370670318604,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 1.1201,
      "step": 390
    },
    {
      "epoch": 3.7037037037037037,
      "grad_norm": 2.397188663482666,
      "learning_rate": 4e-05,
      "loss": 1.0055,
      "step": 400
    },
    {
      "epoch": 3.7962962962962963,
      "grad_norm": 2.5246448516845703,
      "learning_rate": 4.1e-05,
      "loss": 1.1169,
      "step": 410
    },
    {
      "epoch": 3.888888888888889,
      "grad_norm": 2.6020007133483887,
      "learning_rate": 4.2e-05,
      "loss": 1.1265,
      "step": 420
    },
    {
      "epoch": 3.9814814814814814,
      "grad_norm": 2.287853240966797,
      "learning_rate": 4.3e-05,
      "loss": 1.1026,
      "step": 430
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.9977903366088867,
      "eval_runtime": 6.1201,
      "eval_samples_per_second": 35.457,
      "eval_steps_per_second": 4.575,
      "step": 432
    },
    {
      "epoch": 4.074074074074074,
      "grad_norm": 2.3695602416992188,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 1.0023,
      "step": 440
    },
    {
      "epoch": 4.166666666666667,
      "grad_norm": 2.3443470001220703,
      "learning_rate": 4.5e-05,
      "loss": 1.0514,
      "step": 450
    },
    {
      "epoch": 4.2592592592592595,
      "grad_norm": 2.375619411468506,
      "learning_rate": 4.600000000000001e-05,
      "loss": 1.0528,
      "step": 460
    },
    {
      "epoch": 4.351851851851852,
      "grad_norm": 2.252920389175415,
      "learning_rate": 4.7e-05,
      "loss": 1.015,
      "step": 470
    },
    {
      "epoch": 4.444444444444445,
      "grad_norm": 2.2326297760009766,
      "learning_rate": 4.8e-05,
      "loss": 0.9754,
      "step": 480
    },
    {
      "epoch": 4.537037037037037,
      "grad_norm": 2.48502516746521,
      "learning_rate": 4.9e-05,
      "loss": 1.0033,
      "step": 490
    },
    {
      "epoch": 4.62962962962963,
      "grad_norm": 2.1245081424713135,
      "learning_rate": 5e-05,
      "loss": 1.1056,
      "step": 500
    },
    {
      "epoch": 4.722222222222222,
      "grad_norm": 2.6556649208068848,
      "learning_rate": 4.9897959183673474e-05,
      "loss": 1.1047,
      "step": 510
    },
    {
      "epoch": 4.814814814814815,
      "grad_norm": 2.587292194366455,
      "learning_rate": 4.979591836734694e-05,
      "loss": 1.1337,
      "step": 520
    },
    {
      "epoch": 4.907407407407407,
      "grad_norm": 2.511629819869995,
      "learning_rate": 4.969387755102041e-05,
      "loss": 0.9919,
      "step": 530
    },
    {
      "epoch": 5.0,
      "grad_norm": 2.3570332527160645,
      "learning_rate": 4.959183673469388e-05,
      "loss": 1.1183,
      "step": 540
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.9663887023925781,
      "eval_runtime": 6.0961,
      "eval_samples_per_second": 35.597,
      "eval_steps_per_second": 4.593,
      "step": 540
    },
    {
      "epoch": 5.092592592592593,
      "grad_norm": 2.4425299167633057,
      "learning_rate": 4.9489795918367346e-05,
      "loss": 1.0437,
      "step": 550
    },
    {
      "epoch": 5.185185185185185,
      "grad_norm": 2.4423272609710693,
      "learning_rate": 4.938775510204082e-05,
      "loss": 1.0349,
      "step": 560
    },
    {
      "epoch": 5.277777777777778,
      "grad_norm": 2.6967697143554688,
      "learning_rate": 4.928571428571429e-05,
      "loss": 1.0771,
      "step": 570
    },
    {
      "epoch": 5.37037037037037,
      "grad_norm": 2.715165376663208,
      "learning_rate": 4.918367346938776e-05,
      "loss": 1.0648,
      "step": 580
    },
    {
      "epoch": 5.462962962962963,
      "grad_norm": 2.162883996963501,
      "learning_rate": 4.9081632653061225e-05,
      "loss": 0.8796,
      "step": 590
    },
    {
      "epoch": 5.555555555555555,
      "grad_norm": 2.5256292819976807,
      "learning_rate": 4.89795918367347e-05,
      "loss": 0.9705,
      "step": 600
    },
    {
      "epoch": 5.648148148148148,
      "grad_norm": 2.1205894947052,
      "learning_rate": 4.887755102040816e-05,
      "loss": 0.9266,
      "step": 610
    },
    {
      "epoch": 5.7407407407407405,
      "grad_norm": 2.267301321029663,
      "learning_rate": 4.877551020408164e-05,
      "loss": 0.9566,
      "step": 620
    },
    {
      "epoch": 5.833333333333333,
      "grad_norm": 1.9749038219451904,
      "learning_rate": 4.8673469387755104e-05,
      "loss": 0.9473,
      "step": 630
    },
    {
      "epoch": 5.925925925925926,
      "grad_norm": 1.9282876253128052,
      "learning_rate": 4.8571428571428576e-05,
      "loss": 1.0538,
      "step": 640
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.9473459124565125,
      "eval_runtime": 6.1166,
      "eval_samples_per_second": 35.477,
      "eval_steps_per_second": 4.578,
      "step": 648
    },
    {
      "epoch": 6.018518518518518,
      "grad_norm": 2.644582509994507,
      "learning_rate": 4.846938775510204e-05,
      "loss": 1.0539,
      "step": 650
    },
    {
      "epoch": 6.111111111111111,
      "grad_norm": 2.009617805480957,
      "learning_rate": 4.836734693877551e-05,
      "loss": 1.046,
      "step": 660
    },
    {
      "epoch": 6.203703703703703,
      "grad_norm": 2.595609664916992,
      "learning_rate": 4.8265306122448984e-05,
      "loss": 1.0359,
      "step": 670
    },
    {
      "epoch": 6.296296296296296,
      "grad_norm": 2.4265592098236084,
      "learning_rate": 4.816326530612245e-05,
      "loss": 1.0411,
      "step": 680
    },
    {
      "epoch": 6.388888888888889,
      "grad_norm": 2.129399061203003,
      "learning_rate": 4.806122448979592e-05,
      "loss": 0.9558,
      "step": 690
    },
    {
      "epoch": 6.481481481481482,
      "grad_norm": 1.7003389596939087,
      "learning_rate": 4.795918367346939e-05,
      "loss": 0.7978,
      "step": 700
    },
    {
      "epoch": 6.574074074074074,
      "grad_norm": 2.6910665035247803,
      "learning_rate": 4.785714285714286e-05,
      "loss": 0.9917,
      "step": 710
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 2.324225425720215,
      "learning_rate": 4.775510204081633e-05,
      "loss": 0.8403,
      "step": 720
    },
    {
      "epoch": 6.7592592592592595,
      "grad_norm": 2.2420480251312256,
      "learning_rate": 4.76530612244898e-05,
      "loss": 0.9403,
      "step": 730
    },
    {
      "epoch": 6.851851851851852,
      "grad_norm": 2.338881254196167,
      "learning_rate": 4.7551020408163263e-05,
      "loss": 0.9788,
      "step": 740
    },
    {
      "epoch": 6.944444444444445,
      "grad_norm": 2.1825549602508545,
      "learning_rate": 4.744897959183674e-05,
      "loss": 0.9002,
      "step": 750
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.9275290369987488,
      "eval_runtime": 6.1226,
      "eval_samples_per_second": 35.443,
      "eval_steps_per_second": 4.573,
      "step": 756
    },
    {
      "epoch": 7.037037037037037,
      "grad_norm": 2.1356327533721924,
      "learning_rate": 4.7346938775510206e-05,
      "loss": 0.914,
      "step": 760
    },
    {
      "epoch": 7.12962962962963,
      "grad_norm": 2.463949680328369,
      "learning_rate": 4.724489795918368e-05,
      "loss": 1.0133,
      "step": 770
    },
    {
      "epoch": 7.222222222222222,
      "grad_norm": 2.018150806427002,
      "learning_rate": 4.714285714285714e-05,
      "loss": 0.8955,
      "step": 780
    },
    {
      "epoch": 7.314814814814815,
      "grad_norm": 2.2184815406799316,
      "learning_rate": 4.7040816326530614e-05,
      "loss": 0.8296,
      "step": 790
    },
    {
      "epoch": 7.407407407407407,
      "grad_norm": 2.6684212684631348,
      "learning_rate": 4.6938775510204086e-05,
      "loss": 0.9913,
      "step": 800
    },
    {
      "epoch": 7.5,
      "grad_norm": 1.864603042602539,
      "learning_rate": 4.683673469387756e-05,
      "loss": 0.8773,
      "step": 810
    },
    {
      "epoch": 7.592592592592593,
      "grad_norm": 2.27022647857666,
      "learning_rate": 4.673469387755102e-05,
      "loss": 0.882,
      "step": 820
    },
    {
      "epoch": 7.685185185185185,
      "grad_norm": 2.003490924835205,
      "learning_rate": 4.663265306122449e-05,
      "loss": 0.826,
      "step": 830
    },
    {
      "epoch": 7.777777777777778,
      "grad_norm": 2.471712112426758,
      "learning_rate": 4.653061224489796e-05,
      "loss": 0.9671,
      "step": 840
    },
    {
      "epoch": 7.87037037037037,
      "grad_norm": 1.8907184600830078,
      "learning_rate": 4.642857142857143e-05,
      "loss": 0.9296,
      "step": 850
    },
    {
      "epoch": 7.962962962962963,
      "grad_norm": 2.0251400470733643,
      "learning_rate": 4.63265306122449e-05,
      "loss": 0.8863,
      "step": 860
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.9137684106826782,
      "eval_runtime": 6.1216,
      "eval_samples_per_second": 35.448,
      "eval_steps_per_second": 4.574,
      "step": 864
    },
    {
      "epoch": 8.055555555555555,
      "grad_norm": 1.9151498079299927,
      "learning_rate": 4.6224489795918366e-05,
      "loss": 0.9401,
      "step": 870
    },
    {
      "epoch": 8.148148148148149,
      "grad_norm": 2.530686140060425,
      "learning_rate": 4.612244897959184e-05,
      "loss": 0.8946,
      "step": 880
    },
    {
      "epoch": 8.24074074074074,
      "grad_norm": 2.012467622756958,
      "learning_rate": 4.602040816326531e-05,
      "loss": 0.8329,
      "step": 890
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 1.915061354637146,
      "learning_rate": 4.591836734693878e-05,
      "loss": 0.8936,
      "step": 900
    },
    {
      "epoch": 8.425925925925926,
      "grad_norm": 1.805601954460144,
      "learning_rate": 4.5816326530612245e-05,
      "loss": 0.847,
      "step": 910
    },
    {
      "epoch": 8.518518518518519,
      "grad_norm": 1.6720975637435913,
      "learning_rate": 4.5714285714285716e-05,
      "loss": 0.8174,
      "step": 920
    },
    {
      "epoch": 8.61111111111111,
      "grad_norm": 1.9863250255584717,
      "learning_rate": 4.561224489795918e-05,
      "loss": 0.9532,
      "step": 930
    },
    {
      "epoch": 8.703703703703704,
      "grad_norm": 2.065394163131714,
      "learning_rate": 4.551020408163266e-05,
      "loss": 0.8639,
      "step": 940
    },
    {
      "epoch": 8.796296296296296,
      "grad_norm": 1.817810297012329,
      "learning_rate": 4.5408163265306124e-05,
      "loss": 0.9456,
      "step": 950
    },
    {
      "epoch": 8.88888888888889,
      "grad_norm": 1.8941118717193604,
      "learning_rate": 4.5306122448979595e-05,
      "loss": 0.7758,
      "step": 960
    },
    {
      "epoch": 8.981481481481481,
      "grad_norm": 2.022584915161133,
      "learning_rate": 4.520408163265306e-05,
      "loss": 0.8834,
      "step": 970
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.9055169224739075,
      "eval_runtime": 6.1361,
      "eval_samples_per_second": 35.365,
      "eval_steps_per_second": 4.563,
      "step": 972
    },
    {
      "epoch": 9.074074074074074,
      "grad_norm": 1.806429386138916,
      "learning_rate": 4.510204081632654e-05,
      "loss": 0.8713,
      "step": 980
    },
    {
      "epoch": 9.166666666666666,
      "grad_norm": 2.068510055541992,
      "learning_rate": 4.5e-05,
      "loss": 0.835,
      "step": 990
    },
    {
      "epoch": 9.25925925925926,
      "grad_norm": 2.155665874481201,
      "learning_rate": 4.4897959183673474e-05,
      "loss": 0.8469,
      "step": 1000
    },
    {
      "epoch": 9.351851851851851,
      "grad_norm": 2.053439140319824,
      "learning_rate": 4.479591836734694e-05,
      "loss": 0.7927,
      "step": 1010
    },
    {
      "epoch": 9.444444444444445,
      "grad_norm": 2.082602024078369,
      "learning_rate": 4.469387755102041e-05,
      "loss": 0.8438,
      "step": 1020
    },
    {
      "epoch": 9.537037037037036,
      "grad_norm": 1.7908536195755005,
      "learning_rate": 4.459183673469388e-05,
      "loss": 0.7611,
      "step": 1030
    },
    {
      "epoch": 9.62962962962963,
      "grad_norm": 2.022343397140503,
      "learning_rate": 4.448979591836735e-05,
      "loss": 0.9565,
      "step": 1040
    },
    {
      "epoch": 9.722222222222221,
      "grad_norm": 1.7074145078659058,
      "learning_rate": 4.438775510204082e-05,
      "loss": 0.8424,
      "step": 1050
    },
    {
      "epoch": 9.814814814814815,
      "grad_norm": 2.2814290523529053,
      "learning_rate": 4.428571428571428e-05,
      "loss": 0.8455,
      "step": 1060
    },
    {
      "epoch": 9.907407407407408,
      "grad_norm": 1.6928738355636597,
      "learning_rate": 4.418367346938776e-05,
      "loss": 0.8402,
      "step": 1070
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.624342679977417,
      "learning_rate": 4.4081632653061226e-05,
      "loss": 0.8458,
      "step": 1080
    },
    {
      "epoch": 10.0,
      "eval_loss": 0.8946756720542908,
      "eval_runtime": 6.1006,
      "eval_samples_per_second": 35.571,
      "eval_steps_per_second": 4.59,
      "step": 1080
    },
    {
      "epoch": 10.092592592592593,
      "grad_norm": 2.100555658340454,
      "learning_rate": 4.39795918367347e-05,
      "loss": 0.7574,
      "step": 1090
    },
    {
      "epoch": 10.185185185185185,
      "grad_norm": 1.863729476928711,
      "learning_rate": 4.387755102040816e-05,
      "loss": 0.7995,
      "step": 1100
    },
    {
      "epoch": 10.277777777777779,
      "grad_norm": 1.6610119342803955,
      "learning_rate": 4.377551020408163e-05,
      "loss": 0.7978,
      "step": 1110
    },
    {
      "epoch": 10.37037037037037,
      "grad_norm": 1.72215735912323,
      "learning_rate": 4.3673469387755105e-05,
      "loss": 0.7974,
      "step": 1120
    },
    {
      "epoch": 10.462962962962964,
      "grad_norm": 1.6135493516921997,
      "learning_rate": 4.3571428571428576e-05,
      "loss": 0.8075,
      "step": 1130
    },
    {
      "epoch": 10.555555555555555,
      "grad_norm": 1.4614876508712769,
      "learning_rate": 4.346938775510204e-05,
      "loss": 0.7931,
      "step": 1140
    },
    {
      "epoch": 10.648148148148149,
      "grad_norm": 2.0620293617248535,
      "learning_rate": 4.336734693877551e-05,
      "loss": 0.8551,
      "step": 1150
    },
    {
      "epoch": 10.74074074074074,
      "grad_norm": 1.755393147468567,
      "learning_rate": 4.3265306122448984e-05,
      "loss": 0.8111,
      "step": 1160
    },
    {
      "epoch": 10.833333333333334,
      "grad_norm": 1.8821367025375366,
      "learning_rate": 4.3163265306122455e-05,
      "loss": 0.8339,
      "step": 1170
    },
    {
      "epoch": 10.925925925925926,
      "grad_norm": 1.7984529733657837,
      "learning_rate": 4.306122448979592e-05,
      "loss": 0.8441,
      "step": 1180
    },
    {
      "epoch": 11.0,
      "eval_loss": 0.8896685242652893,
      "eval_runtime": 6.0826,
      "eval_samples_per_second": 35.676,
      "eval_steps_per_second": 4.603,
      "step": 1188
    },
    {
      "epoch": 11.018518518518519,
      "grad_norm": 1.764595627784729,
      "learning_rate": 4.295918367346939e-05,
      "loss": 0.8379,
      "step": 1190
    },
    {
      "epoch": 11.11111111111111,
      "grad_norm": 1.6225823163986206,
      "learning_rate": 4.2857142857142856e-05,
      "loss": 0.8306,
      "step": 1200
    },
    {
      "epoch": 11.203703703703704,
      "grad_norm": 1.726325511932373,
      "learning_rate": 4.275510204081633e-05,
      "loss": 0.7653,
      "step": 1210
    },
    {
      "epoch": 11.296296296296296,
      "grad_norm": 1.9948880672454834,
      "learning_rate": 4.26530612244898e-05,
      "loss": 0.8241,
      "step": 1220
    },
    {
      "epoch": 11.38888888888889,
      "grad_norm": 2.0167236328125,
      "learning_rate": 4.2551020408163264e-05,
      "loss": 0.7371,
      "step": 1230
    },
    {
      "epoch": 11.481481481481481,
      "grad_norm": 1.988534688949585,
      "learning_rate": 4.2448979591836735e-05,
      "loss": 0.8339,
      "step": 1240
    },
    {
      "epoch": 11.574074074074074,
      "grad_norm": 1.8206794261932373,
      "learning_rate": 4.234693877551021e-05,
      "loss": 0.7689,
      "step": 1250
    },
    {
      "epoch": 11.666666666666666,
      "grad_norm": 1.6255253553390503,
      "learning_rate": 4.224489795918368e-05,
      "loss": 0.7842,
      "step": 1260
    },
    {
      "epoch": 11.75925925925926,
      "grad_norm": 2.0595221519470215,
      "learning_rate": 4.214285714285714e-05,
      "loss": 0.7761,
      "step": 1270
    },
    {
      "epoch": 11.851851851851851,
      "grad_norm": 1.789508581161499,
      "learning_rate": 4.2040816326530615e-05,
      "loss": 0.7895,
      "step": 1280
    },
    {
      "epoch": 11.944444444444445,
      "grad_norm": 1.8069883584976196,
      "learning_rate": 4.193877551020408e-05,
      "loss": 0.7291,
      "step": 1290
    },
    {
      "epoch": 12.0,
      "eval_loss": 0.8817369341850281,
      "eval_runtime": 6.1266,
      "eval_samples_per_second": 35.42,
      "eval_steps_per_second": 4.57,
      "step": 1296
    },
    {
      "epoch": 12.037037037037036,
      "grad_norm": 1.8367868661880493,
      "learning_rate": 4.183673469387756e-05,
      "loss": 0.7142,
      "step": 1300
    },
    {
      "epoch": 12.12962962962963,
      "grad_norm": 2.039747953414917,
      "learning_rate": 4.173469387755102e-05,
      "loss": 0.7895,
      "step": 1310
    },
    {
      "epoch": 12.222222222222221,
      "grad_norm": 1.6049888134002686,
      "learning_rate": 4.1632653061224494e-05,
      "loss": 0.7458,
      "step": 1320
    },
    {
      "epoch": 12.314814814814815,
      "grad_norm": 2.007927656173706,
      "learning_rate": 4.153061224489796e-05,
      "loss": 0.7664,
      "step": 1330
    },
    {
      "epoch": 12.407407407407407,
      "grad_norm": 1.7847492694854736,
      "learning_rate": 4.1428571428571437e-05,
      "loss": 0.7887,
      "step": 1340
    },
    {
      "epoch": 12.5,
      "grad_norm": 1.7445330619812012,
      "learning_rate": 4.13265306122449e-05,
      "loss": 0.7461,
      "step": 1350
    },
    {
      "epoch": 12.592592592592592,
      "grad_norm": 1.981749176979065,
      "learning_rate": 4.122448979591837e-05,
      "loss": 0.776,
      "step": 1360
    },
    {
      "epoch": 12.685185185185185,
      "grad_norm": 1.5358504056930542,
      "learning_rate": 4.112244897959184e-05,
      "loss": 0.786,
      "step": 1370
    },
    {
      "epoch": 12.777777777777779,
      "grad_norm": 1.8904120922088623,
      "learning_rate": 4.102040816326531e-05,
      "loss": 0.7253,
      "step": 1380
    },
    {
      "epoch": 12.87037037037037,
      "grad_norm": 1.9225481748580933,
      "learning_rate": 4.091836734693878e-05,
      "loss": 0.6833,
      "step": 1390
    },
    {
      "epoch": 12.962962962962964,
      "grad_norm": 1.6069283485412598,
      "learning_rate": 4.0816326530612245e-05,
      "loss": 0.7873,
      "step": 1400
    },
    {
      "epoch": 13.0,
      "eval_loss": 0.8773294687271118,
      "eval_runtime": 6.1086,
      "eval_samples_per_second": 35.524,
      "eval_steps_per_second": 4.584,
      "step": 1404
    },
    {
      "epoch": 13.055555555555555,
      "grad_norm": 1.6087497472763062,
      "learning_rate": 4.0714285714285717e-05,
      "loss": 0.7522,
      "step": 1410
    },
    {
      "epoch": 13.148148148148149,
      "grad_norm": 1.6875027418136597,
      "learning_rate": 4.061224489795918e-05,
      "loss": 0.7553,
      "step": 1420
    },
    {
      "epoch": 13.24074074074074,
      "grad_norm": 1.663444995880127,
      "learning_rate": 4.051020408163265e-05,
      "loss": 0.6798,
      "step": 1430
    },
    {
      "epoch": 13.333333333333334,
      "grad_norm": 1.5151546001434326,
      "learning_rate": 4.0408163265306124e-05,
      "loss": 0.7007,
      "step": 1440
    },
    {
      "epoch": 13.425925925925926,
      "grad_norm": 1.6693443059921265,
      "learning_rate": 4.0306122448979596e-05,
      "loss": 0.6847,
      "step": 1450
    },
    {
      "epoch": 13.518518518518519,
      "grad_norm": 1.6043245792388916,
      "learning_rate": 4.020408163265306e-05,
      "loss": 0.7369,
      "step": 1460
    },
    {
      "epoch": 13.61111111111111,
      "grad_norm": 1.994976282119751,
      "learning_rate": 4.010204081632653e-05,
      "loss": 0.7282,
      "step": 1470
    },
    {
      "epoch": 13.703703703703704,
      "grad_norm": 1.938570261001587,
      "learning_rate": 4e-05,
      "loss": 0.7327,
      "step": 1480
    },
    {
      "epoch": 13.796296296296296,
      "grad_norm": 1.6336486339569092,
      "learning_rate": 3.9897959183673475e-05,
      "loss": 0.7622,
      "step": 1490
    },
    {
      "epoch": 13.88888888888889,
      "grad_norm": 1.804373860359192,
      "learning_rate": 3.979591836734694e-05,
      "loss": 0.7308,
      "step": 1500
    },
    {
      "epoch": 13.981481481481481,
      "grad_norm": 1.84751558303833,
      "learning_rate": 3.969387755102041e-05,
      "loss": 0.7352,
      "step": 1510
    },
    {
      "epoch": 14.0,
      "eval_loss": 0.87908935546875,
      "eval_runtime": 6.1256,
      "eval_samples_per_second": 35.425,
      "eval_steps_per_second": 4.571,
      "step": 1512
    },
    {
      "epoch": 14.074074074074074,
      "grad_norm": 1.5732258558273315,
      "learning_rate": 3.9591836734693876e-05,
      "loss": 0.7042,
      "step": 1520
    },
    {
      "epoch": 14.166666666666666,
      "grad_norm": 1.297896385192871,
      "learning_rate": 3.9489795918367354e-05,
      "loss": 0.727,
      "step": 1530
    },
    {
      "epoch": 14.25925925925926,
      "grad_norm": 1.5997477769851685,
      "learning_rate": 3.938775510204082e-05,
      "loss": 0.7552,
      "step": 1540
    },
    {
      "epoch": 14.351851851851851,
      "grad_norm": 1.6768512725830078,
      "learning_rate": 3.928571428571429e-05,
      "loss": 0.6324,
      "step": 1550
    },
    {
      "epoch": 14.444444444444445,
      "grad_norm": 1.8229694366455078,
      "learning_rate": 3.9183673469387755e-05,
      "loss": 0.7031,
      "step": 1560
    },
    {
      "epoch": 14.537037037037036,
      "grad_norm": 1.5124726295471191,
      "learning_rate": 3.9081632653061226e-05,
      "loss": 0.6497,
      "step": 1570
    },
    {
      "epoch": 14.62962962962963,
      "grad_norm": 1.4710452556610107,
      "learning_rate": 3.89795918367347e-05,
      "loss": 0.7231,
      "step": 1580
    },
    {
      "epoch": 14.722222222222221,
      "grad_norm": 1.5785446166992188,
      "learning_rate": 3.887755102040816e-05,
      "loss": 0.7551,
      "step": 1590
    },
    {
      "epoch": 14.814814814814815,
      "grad_norm": 1.6528161764144897,
      "learning_rate": 3.8775510204081634e-05,
      "loss": 0.6729,
      "step": 1600
    },
    {
      "epoch": 14.907407407407408,
      "grad_norm": 1.6978076696395874,
      "learning_rate": 3.86734693877551e-05,
      "loss": 0.6895,
      "step": 1610
    },
    {
      "epoch": 15.0,
      "grad_norm": 1.6521323919296265,
      "learning_rate": 3.857142857142858e-05,
      "loss": 0.7342,
      "step": 1620
    },
    {
      "epoch": 15.0,
      "eval_loss": 0.8712882399559021,
      "eval_runtime": 6.1181,
      "eval_samples_per_second": 35.469,
      "eval_steps_per_second": 4.577,
      "step": 1620
    },
    {
      "epoch": 15.092592592592593,
      "grad_norm": 1.5886310338974,
      "learning_rate": 3.846938775510204e-05,
      "loss": 0.6747,
      "step": 1630
    },
    {
      "epoch": 15.185185185185185,
      "grad_norm": 1.5488721132278442,
      "learning_rate": 3.836734693877551e-05,
      "loss": 0.654,
      "step": 1640
    },
    {
      "epoch": 15.277777777777779,
      "grad_norm": 2.0289924144744873,
      "learning_rate": 3.826530612244898e-05,
      "loss": 0.7,
      "step": 1650
    },
    {
      "epoch": 15.37037037037037,
      "grad_norm": 1.610443115234375,
      "learning_rate": 3.8163265306122456e-05,
      "loss": 0.6337,
      "step": 1660
    },
    {
      "epoch": 15.462962962962964,
      "grad_norm": 1.5574969053268433,
      "learning_rate": 3.806122448979592e-05,
      "loss": 0.6845,
      "step": 1670
    },
    {
      "epoch": 15.555555555555555,
      "grad_norm": 1.8181085586547852,
      "learning_rate": 3.795918367346939e-05,
      "loss": 0.7064,
      "step": 1680
    },
    {
      "epoch": 15.648148148148149,
      "grad_norm": 1.5650290250778198,
      "learning_rate": 3.785714285714286e-05,
      "loss": 0.6926,
      "step": 1690
    },
    {
      "epoch": 15.74074074074074,
      "grad_norm": 1.2780072689056396,
      "learning_rate": 3.775510204081633e-05,
      "loss": 0.6491,
      "step": 1700
    },
    {
      "epoch": 15.833333333333334,
      "grad_norm": 1.6185131072998047,
      "learning_rate": 3.76530612244898e-05,
      "loss": 0.6513,
      "step": 1710
    },
    {
      "epoch": 15.925925925925926,
      "grad_norm": 1.907747507095337,
      "learning_rate": 3.7551020408163264e-05,
      "loss": 0.7232,
      "step": 1720
    },
    {
      "epoch": 16.0,
      "eval_loss": 0.8773290514945984,
      "eval_runtime": 6.0976,
      "eval_samples_per_second": 35.588,
      "eval_steps_per_second": 4.592,
      "step": 1728
    },
    {
      "epoch": 16.01851851851852,
      "grad_norm": 2.1722702980041504,
      "learning_rate": 3.7448979591836736e-05,
      "loss": 0.7327,
      "step": 1730
    },
    {
      "epoch": 16.11111111111111,
      "grad_norm": 1.6577826738357544,
      "learning_rate": 3.734693877551021e-05,
      "loss": 0.6493,
      "step": 1740
    },
    {
      "epoch": 16.203703703703702,
      "grad_norm": 1.4781925678253174,
      "learning_rate": 3.724489795918368e-05,
      "loss": 0.708,
      "step": 1750
    },
    {
      "epoch": 16.296296296296298,
      "grad_norm": 1.6048864126205444,
      "learning_rate": 3.7142857142857143e-05,
      "loss": 0.6117,
      "step": 1760
    },
    {
      "epoch": 16.38888888888889,
      "grad_norm": 1.688401460647583,
      "learning_rate": 3.7040816326530615e-05,
      "loss": 0.6737,
      "step": 1770
    },
    {
      "epoch": 16.48148148148148,
      "grad_norm": 1.895817756652832,
      "learning_rate": 3.693877551020408e-05,
      "loss": 0.6192,
      "step": 1780
    },
    {
      "epoch": 16.574074074074073,
      "grad_norm": 1.6540168523788452,
      "learning_rate": 3.683673469387755e-05,
      "loss": 0.5964,
      "step": 1790
    },
    {
      "epoch": 16.666666666666668,
      "grad_norm": 1.562557578086853,
      "learning_rate": 3.673469387755102e-05,
      "loss": 0.6957,
      "step": 1800
    },
    {
      "epoch": 16.75925925925926,
      "grad_norm": 1.7771856784820557,
      "learning_rate": 3.6632653061224494e-05,
      "loss": 0.6964,
      "step": 1810
    },
    {
      "epoch": 16.85185185185185,
      "grad_norm": 1.4167845249176025,
      "learning_rate": 3.653061224489796e-05,
      "loss": 0.6531,
      "step": 1820
    },
    {
      "epoch": 16.944444444444443,
      "grad_norm": 1.2206259965896606,
      "learning_rate": 3.642857142857143e-05,
      "loss": 0.6469,
      "step": 1830
    },
    {
      "epoch": 17.0,
      "eval_loss": 0.8759772181510925,
      "eval_runtime": 6.1306,
      "eval_samples_per_second": 35.396,
      "eval_steps_per_second": 4.567,
      "step": 1836
    },
    {
      "epoch": 17.037037037037038,
      "grad_norm": 1.46381676197052,
      "learning_rate": 3.63265306122449e-05,
      "loss": 0.6586,
      "step": 1840
    },
    {
      "epoch": 17.12962962962963,
      "grad_norm": 1.6840550899505615,
      "learning_rate": 3.622448979591837e-05,
      "loss": 0.6465,
      "step": 1850
    },
    {
      "epoch": 17.22222222222222,
      "grad_norm": 1.3269089460372925,
      "learning_rate": 3.612244897959184e-05,
      "loss": 0.664,
      "step": 1860
    },
    {
      "epoch": 17.314814814814813,
      "grad_norm": 1.715043544769287,
      "learning_rate": 3.602040816326531e-05,
      "loss": 0.5988,
      "step": 1870
    },
    {
      "epoch": 17.40740740740741,
      "grad_norm": 1.6914726495742798,
      "learning_rate": 3.5918367346938774e-05,
      "loss": 0.6435,
      "step": 1880
    },
    {
      "epoch": 17.5,
      "grad_norm": 1.5440973043441772,
      "learning_rate": 3.5816326530612245e-05,
      "loss": 0.6381,
      "step": 1890
    },
    {
      "epoch": 17.59259259259259,
      "grad_norm": 1.38633131980896,
      "learning_rate": 3.571428571428572e-05,
      "loss": 0.5688,
      "step": 1900
    },
    {
      "epoch": 17.685185185185187,
      "grad_norm": 1.6471803188323975,
      "learning_rate": 3.561224489795918e-05,
      "loss": 0.693,
      "step": 1910
    },
    {
      "epoch": 17.77777777777778,
      "grad_norm": 1.7276591062545776,
      "learning_rate": 3.551020408163265e-05,
      "loss": 0.6197,
      "step": 1920
    },
    {
      "epoch": 17.87037037037037,
      "grad_norm": 1.5852001905441284,
      "learning_rate": 3.5408163265306125e-05,
      "loss": 0.6248,
      "step": 1930
    },
    {
      "epoch": 17.962962962962962,
      "grad_norm": 1.5775552988052368,
      "learning_rate": 3.5306122448979596e-05,
      "loss": 0.6624,
      "step": 1940
    },
    {
      "epoch": 18.0,
      "eval_loss": 0.8712695240974426,
      "eval_runtime": 6.1211,
      "eval_samples_per_second": 35.451,
      "eval_steps_per_second": 4.574,
      "step": 1944
    }
  ],
  "logging_steps": 10,
  "max_steps": 5400,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4063613681664000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
